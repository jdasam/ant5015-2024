{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-DJvoIiAUj6P"
   },
   "source": [
    "# Assignment 2: Music Auto-tagging Model\n",
    "- In this assignment, you will train your auto-tagging model using PyTorch\n",
    "- The dataset is from MagnaTagATune\n",
    "  - Randomly selected 8000 mp3 files\n",
    "  - 5000 files for training, 1000 for validation, 2000 for test  \n",
    "- Every code cell before the Problem 0 has to be ran without modification or error\n",
    "- You have to submit three files:\n",
    "  - Notebook in ipynb\n",
    "  - Py file of the completed code\n",
    "  - Model file in pt\n",
    " \n",
    "- Problem 1: Complete three dataset classes (16 pts)\n",
    "- Probelm 2: Train your own model (15 pts)\n",
    "- Problem 3: Implement Convolutional Neural Network (20 pts)\n",
    "- Problem 4: Complete Binary Cross Entropy function (4 pts)\n",
    "- Problem 5: Complete Precision-Recall Area Under Curve function (20 pts)\n",
    "- Problem 6: Find the best threshold (15 pts)\n",
    "- Problem 7: Load audio and make prediction (10 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SKLjUzcbUj6W"
   },
   "source": [
    "## 0. Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d5LcyB2rUj6W",
    "outputId": "23958e04-69d3-4080-f143-f4b802691aaf"
   },
   "outputs": [],
   "source": [
    "DEV = 'cuda' # select your device 'cpu' or 'cuda'\n",
    "\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Union, Callable\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "\n",
    "def save_fig_with_date(figname:str):\n",
    "  plt.savefig(f\"{figname}_{datetime.now().strftime('%m_%d_%H_%M_%S')}.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "aiocvB4v8jCC"
   },
   "source": [
    "- Download dataset from Google Drive link and Unzip at `MTAT_SMALL/`\n",
    "  - You can also download it from [OneDrive Link](https://sogang365-my.sharepoint.com/:u:/g/personal/dasaem_jeong_o365_sogang_ac_kr/EdkHWV-qvxBEi-d0Ua73VG4BEp7EZO7HMvrXsWqeJvMJzg?e=Yi4jf0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hEjKpTS_WCu4"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade gdown\n",
    "!gdown --id 15e9E3oZdudErkPKwb0rCAiZXkPxdZkV6\n",
    "!unzip -q mtat_8000.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VOSCuOJMUj6W"
   },
   "source": [
    "## Problem 1. Complete Dataset Class (21 pts)\n",
    "- In this problem, you have to implement three ways to load the data\n",
    "    - 1) Load audio file and resample every time the data is called \n",
    "    - 2) Save pre-processed data in .pt file and load it every time the data is called \n",
    "    - 3) Load every audio file on memory before the training starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "T_lpbZK1Uj6X"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "You don't have to change this cell\n",
    "'''\n",
    "class MTATDataset:\n",
    "  def __init__(self, dir_path:str, split:str='train', num_max_data:int=4000, sr:int=16000):\n",
    "    self.dir = Path(dir_path)\n",
    "    self.labels = pd.read_csv(self.dir / \"meta.csv\", index_col=[0])\n",
    "    self.sr = sr\n",
    "\n",
    "    if split==\"train\":\n",
    "      sub_dir_ids = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c']\n",
    "    elif split=='valid':\n",
    "      sub_dir_ids = ['d']\n",
    "    else: #test\n",
    "      sub_dir_ids = ['e', 'f', 'g']\n",
    "\n",
    "    is_in_set = [True if x[0] in sub_dir_ids else False for x in self.labels['mp3_path'].values.astype('str')]\n",
    "    self.labels = self.labels.iloc[is_in_set]\n",
    "    self.labels = self.labels[:num_max_data]\n",
    "    self.vocab = self.labels.columns.values[1:-1]\n",
    "    self.label_tensor = self.convert_label_to_tensor()\n",
    "  \n",
    "  def convert_label_to_tensor(self):\n",
    "    return torch.LongTensor(self.labels.values[:, 1:-1].astype('bool'))\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.labels)\n",
    "  \n",
    "\n",
    "MTAT_DIR = Path('MTAT_SMALL/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Check how baseline dataset looks like\n",
    "'''\n",
    "\n",
    "base_set = MTATDataset(MTAT_DIR)\n",
    "\n",
    "'''\n",
    "metadata of dataset is stored in self.labels\n",
    "'''\n",
    "base_set.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "You can use labels['mp3_path'].iloc\n",
    "'''\n",
    "target_idx = 0 \n",
    "\n",
    "path_to_target_idx = base_set.labels['mp3_path'].iloc[target_idx]\n",
    "print(path_to_target_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "label of each tensor is also stored in self.label_tensor\n",
    "'''\n",
    "base_set.label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OnTheFlyDataset(MTATDataset):\n",
    "  def __init__(self, dir_path:str, split:str='train', num_max_data:int=4000, sr:int=16000):\n",
    "    super().__init__(dir_path, split, num_max_data, sr)\n",
    "    \n",
    "  def __getitem__(self, idx):\n",
    "    '''\n",
    "    __getitem__ returns a corresponding idx-th data sample among the dataset.\n",
    "    In music-tag dataset, it has to return (audio_sample, label) of idx-th data.\n",
    "    \n",
    "    OnTheFlyDataset loads the audio file whenever this __getitem__ function is called.\n",
    "    In this function, you have to implement these things\n",
    "    \n",
    "    1) Get the file path of idx-th data sample (use self.labels['mp3_path'])\n",
    "    2) Load the audio of that file path\n",
    "    3) Resample the audio sample into frequency of self.sr (You can use torchaudio.functional.resample)\n",
    "    4) Return resampled audio sample and the label (tag data) of the data sample\n",
    "    \n",
    "    Output\n",
    "      audio_sample (torch.FloatTensor):  \n",
    "      label (torch.FloatTensor): A tensor with shape of 50 dimension. Each dimension has value either 0 or 1\n",
    "                                 If n-th dimension's value is 1, it means n-th tag is True for this data sample\n",
    "    \n",
    "    TODO: Complete this function\n",
    "    '''\n",
    "    audio_sample = None\n",
    "    label = None\n",
    "\n",
    "    \n",
    "    return audio_sample, label\n",
    "\n",
    "dummy_set = OnTheFlyDataset(MTAT_DIR, split='train', num_max_data=100)\n",
    "audio, label = dummy_set[0]\n",
    "assert audio.ndim == 1, \"Number of dimensions of audio tensor has to be 1. Use audio[0] or audio.mean(dim=0) to reduce it\"\n",
    "assert len(audio) == 465984, \"Audio tensor has wrong shape\"\n",
    "assert label.ndim == 1, \"Number of dimensions of label tensor has to be 1\"\n",
    "\n",
    "print(\"Complete!\")\n",
    "\n",
    "ipd.display(ipd.Audio(audio, rate=dummy_set.sr))\n",
    "print(dummy_set.vocab[torch.where(label)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreProcessDataset(MTATDataset):\n",
    "  def __init__(self, dir_path:str, split:str='train', num_max_data:int=4000, sr:int=16000):\n",
    "    super().__init__(dir_path, split, num_max_data, sr)\n",
    "    \n",
    "    self.pre_process_and_save_data()\n",
    "    \n",
    "  def pre_process_and_save_data(self):\n",
    "    '''\n",
    "    self.pre_process_and_save_data loads every audio sample in the dataset, resample it, and save it into pt file.\n",
    "    In this function, you have to implement these things\n",
    "    \n",
    "    1) For every data sample in the dataset, check whether pre-processed data already exists\n",
    "      - You can get data sample path by self.labels['mp3_path'].values\n",
    "      - path of pre-processed data can be in the same directory, but with different suffix.\n",
    "      - You can make it with Path(mp3_path).with_suffix('.pt')\n",
    "    2) If it doesn't exist, do follow things\n",
    "      a) Load audio file \n",
    "      b) Resample the audio file with samplerate of self.sr\n",
    "      c) Get label of this audio file\n",
    "      d) Save {'audio': audio_tensor, 'label':label_tensor} with torch.save\n",
    "    \n",
    "    Output\n",
    "      None\n",
    "    \n",
    "    TODO: Complete this function\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    \n",
    "  def __getitem__(self, idx):\n",
    "    '''\n",
    "    __getitem__ returns a corresponding idx-th data sample among the dataset.\n",
    "    In music-tag dataset, it has to return (audio_sample, label) of idx-th data.\n",
    "    \n",
    "    PreProcessDataset loads the pre-processed pt file whenever this __getitem__ function is called.\n",
    "    In this function, you have to implement these things\n",
    "    \n",
    "    1) Get the pt file path of idx-th data sample (use self.labels)\n",
    "    2) Load the pre-procssed data of that file path (use torch.load)\n",
    "    3) Return the audio sample and the label (tag data) of the data sample\n",
    "\n",
    "    TODO: Complete this function\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    return audio_sample, label\n",
    "  \n",
    "dummy_set = PreProcessDataset(MTAT_DIR, split='train', num_max_data=100)\n",
    "audio, label = dummy_set[15]\n",
    "assert audio.ndim == 1, \"Number of dimensions of audio tensor has to be 1. Use audio[0] or audio.mean(dim=0) to reduce it\"\n",
    "assert len(audio) == 465984, \"Audio tensor has wrong shape\"\n",
    "assert label.ndim == 1, \"Number of dimensions of label tensor has to be 1\"\n",
    "assert (MTAT_DIR / '2/zephyrus-angelus-11-ave_maria__virgo_serena_josquin_des_prez-0-29.pt').exists(), \"pt file is not generated\"\n",
    "assert torch.load(MTAT_DIR / '2/zephyrus-angelus-11-ave_maria__virgo_serena_josquin_des_prez-0-29.pt')['audio'].shape == (465984,), \"Audio tensor is not saved properly\"\n",
    "\n",
    "ipd.display(ipd.Audio(audio, rate=dummy_set.sr))\n",
    "print(dummy_set.vocab[torch.where(label)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class OnMemoryDataset(MTATDataset):\n",
    "  def __init__(self, dir_path:str, split:str='train', num_max_data:int=4000, sr:int=16000):\n",
    "    super().__init__(dir_path, split, num_max_data, sr)\n",
    "    \n",
    "    self.loaded_audios = self.load_audio()\n",
    "    \n",
    "  def load_audio(self):\n",
    "    '''\n",
    "    In this function, you have to load all the audio file in the dataset, and resample them, \n",
    "    and store the data on the memory as a python variable\n",
    "    \n",
    "    For each data in the dataset,\n",
    "      a) Load Audio\n",
    "      b) Resample it to self.sr\n",
    "      c) Append it to total_audio_datas\n",
    "    \n",
    "    Output:\n",
    "      total_audio_datas (list): A list of torch.FloatTensor. i-th item of the list corresponds to the audio sample of i-th data\n",
    "                                Each item is an audio sample in torch.FloatTensor with sampling rate of self.sr \n",
    "    '''\n",
    "    total_audio_datas = []\n",
    "    \n",
    "    ### Write your code from here\n",
    "\n",
    "    \n",
    "    return total_audio_datas\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    '''\n",
    "    __getitem__ returns a corresponding idx-th data sample among the dataset.\n",
    "    In music-tag dataset, it has to return (audio_sample, label) of idx-th data.\n",
    "    \n",
    "    OnMemoryDataset returns the pre-loaded audio data that is aved on self.loaded_audios whenever this __getitem__ function is called.\n",
    "    In this function, you have to implement these things\n",
    "    \n",
    "    1) Load the pre-procssed audio data from self.loaded_audios\n",
    "    2) Return the audio sample and the label (tag data) of the data sample\n",
    "\n",
    "    TODO: Complete this function\n",
    "    '''\n",
    "    \n",
    "    return audio_sample, label\n",
    "  \n",
    "dummy_set = OnMemoryDataset(MTAT_DIR, split='train', num_max_data=50)\n",
    "audio, label = dummy_set[10]\n",
    "assert audio.ndim == 1, \"Number of dimensions of audio tensor has to be 1. Use audio[0] or audio.mean(dim=0) to reduce it\"\n",
    "assert audio.ndim == 1, \"Number of dimensions of audio tensor has to be 1. Use audio[0] or audio.mean(dim=0) to reduce it\"\n",
    "assert len(audio) == 465984, \"Audio tensor has wrong shape\"\n",
    "assert dummy_set.loaded_audios[0].shape == (465984,), \"Audio tensor is not saved properly\"\n",
    "\n",
    "ipd.display(ipd.Audio(audio, rate=dummy_set.sr))\n",
    "print(dummy_set.vocab[torch.where(label)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Dataset\n",
    "- You can select one of your implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_dataset_class = PreProcessDataset # One of OnTheFlyDataset, PreProcessDataset, or OnMemoryDataset\n",
    "# your_dataset_class = OnMemoryDataset\n",
    "'''\n",
    "Based on your memory size or storage size, you can change the num_max_data\n",
    "'''\n",
    "trainset = your_dataset_class(MTAT_DIR, split='train', num_max_data=5000)\n",
    "validset = your_dataset_class(MTAT_DIR, split='valid', num_max_data=1000)\n",
    "testset = your_dataset_class(MTAT_DIR, split='test', num_max_data=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rIPU7DxUUj6Y"
   },
   "source": [
    "#### DataLoader\n",
    "- Define `DataLoader` using the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "bPauowdkUj6Z"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=0) # you can speed up with num_workers=4 if you have multiple cpu core\n",
    "valid_loader = DataLoader(validset, batch_size=128, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(testset, batch_size=128, shuffle=False, num_workers=0)\n",
    "\n",
    "batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D2kAXFFZUj6a"
   },
   "source": [
    "## Preparation: Define Neural Network\n",
    "- Define the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "TB0nTbt7Uj6a"
   },
   "outputs": [],
   "source": [
    "class SpecModel(nn.Module):\n",
    "  def __init__(self, sr:int, n_fft:int, hop_length:int, n_mels:int):\n",
    "    super().__init__()\n",
    "    self.mel_converter = torchaudio.transforms.MelSpectrogram(sample_rate=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
    "    self.db_converter = torchaudio.transforms.AmplitudeToDB()\n",
    "  \n",
    "  def forward(self, x):\n",
    "    mel_spec = self.mel_converter(x)\n",
    "    return self.db_converter(mel_spec)\n",
    "\n",
    "class AudioModel(nn.Module):\n",
    "  def __init__(self, sr:int, n_fft:int, hop_length:int, n_mels:int, hidden_size:int, num_output:int):\n",
    "    super().__init__()\n",
    "    self.sr = sr\n",
    "    self.spec_converter = SpecModel(sr, n_fft, hop_length, n_mels)\n",
    "    self.conv_layer = nn.Sequential(\n",
    "      nn.Conv1d(n_mels, out_channels=hidden_size, kernel_size=3),\n",
    "      nn.MaxPool1d(3),\n",
    "      nn.ReLU(),\n",
    "      nn.Conv1d(hidden_size, out_channels=hidden_size, kernel_size=3),\n",
    "      nn.MaxPool1d(3),\n",
    "      nn.ReLU(),     \n",
    "      nn.Conv1d(hidden_size, out_channels=hidden_size, kernel_size=3),\n",
    "      nn.MaxPool1d(3),\n",
    "      nn.ReLU(),\n",
    "    )\n",
    "    self.final_layer = nn.Linear(hidden_size, num_output)\n",
    "\n",
    "  def get_spec(self, x):\n",
    "    '''\n",
    "    Get result of self.spec_converter\n",
    "    x (torch.Tensor): audio samples (num_batch_size X num_audio_samples)\n",
    "    '''\n",
    "    return self.spec_converter(x)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    spec = self.get_spec(x) # num_batch X num_mel_bins X num_time_bins\n",
    "    out = self.conv_layer(spec)\n",
    "    out = torch.max(out, dim=-1)[0] # select [0] because torch.max outputs tuple of (value, index)\n",
    "    out = self.final_layer(out)\n",
    "    out = torch.sigmoid(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0UIl_uvUj6b"
   },
   "source": [
    "## 3. Train the Network\n",
    "- First, just run the cells below so that you can obtain the first result\n",
    "- Plot the training loss and validation accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "6VBnZiX7Uj6b"
   },
   "outputs": [],
   "source": [
    "def get_tpr_fpr(pred:torch.Tensor, target:torch.Tensor, threshold:float=0.5):\n",
    "  thresh_pred = pred> threshold\n",
    "  p = torch.sum(target == 1)\n",
    "  tp = torch.sum((thresh_pred==1) * (target==1))\n",
    "  n = torch.sum(target == 0)\n",
    "  fp = torch.sum((thresh_pred==1) * (target==0))\n",
    "  return tp/p, fp/n\n",
    "\n",
    "def get_roc_auc(pred:torch.Tensor, target:torch.Tensor, num_grid=500):\n",
    "  auc = 0\n",
    "  prev_fpr = 0\n",
    "  for thresh in reversed(torch.linspace(0,1,num_grid)):\n",
    "    tpr, fpr = get_tpr_fpr(pred, target, threshold=thresh)\n",
    "    auc += tpr * (fpr-prev_fpr)\n",
    "    prev_fpr = fpr\n",
    "  return auc\n",
    "\n",
    "def train_model(model:nn.Module, train_loader:DataLoader, valid_loader:DataLoader, optimizer:torch.optim.Optimizer, num_epochs:int, loss_func, device='cuda'):\n",
    "  loss_records =[] \n",
    "  valid_acc_records = []\n",
    "  model.vocab = train_loader.dataset.vocab\n",
    "  model.train() # Set model to train mode\n",
    "  for epoch in tqdm(range(num_epochs)):\n",
    "    for batch in train_loader:\n",
    "      optimizer.zero_grad() # Rest gradient of every parameters in optimizer (every parameters in the model)\n",
    "      audio, label = batch\n",
    "      audio = audio.to(device)\n",
    "      label = label.to(device)\n",
    "      pred = model(audio)\n",
    "      loss = loss_func(pred, label.float())\n",
    "      loss.backward() # Run backpropagation\n",
    "      optimizer.step() # Update parameters\n",
    "      loss_records.append(loss.item())\n",
    "    valid_acc = validate_model(model, valid_loader, device)\n",
    "    valid_acc_records.append(valid_acc.item())\n",
    "  return {\"loss\": loss_records, \"valid_acc\": valid_acc_records}\n",
    "\n",
    "def validate_model(model, valid_loader, device, acc_func=get_roc_auc):\n",
    "  valid_acc = 0\n",
    "  model.eval()\n",
    "  model.to(device)\n",
    "  with torch.no_grad():\n",
    "    for batch in valid_loader:\n",
    "      audio, label = batch\n",
    "      pred = model(audio.to(device))\n",
    "      auc = acc_func(pred, label.to(device))\n",
    "      valid_acc += auc * len(label)\n",
    "  model.train()\n",
    "  return valid_acc / len(valid_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PTHIVXvNUj6c",
    "outputId": "1f9d2e84-ad4c-4e50-b7b7-031fd6785620",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Train the default model\n",
    "'''\n",
    "\n",
    "model = AudioModel(sr=16000, n_fft=1024, hop_length=512, n_mels=48, num_output=50, hidden_size=32)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "model = model.to(DEV)\n",
    "loss_func = torch.nn.BCELoss()\n",
    "train_record = train_model(model, train_loader, valid_loader, optimizer, num_epochs=30, loss_func=loss_func, device=DEV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cUCYjyeyUj6c"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_record['loss'])\n",
    "save_fig_with_date('default_train_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WJ92F5T1Uj6c"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_record['valid_acc'])\n",
    "save_fig_with_date('default_train_valid_acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3yzROUqOUj6e"
   },
   "source": [
    "### Probelm 2. Try Various Settings and Find Best Model (15 pts)\n",
    "- You can try different `n_fft`, `n_mels`, or `hidden_size`, or different `conv_layer` in your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I0h6XoqUUj6f"
   },
   "outputs": [],
   "source": [
    "class YourModel(AudioModel):\n",
    "  def __init__(self, sr, n_fft, hop_length, n_mels, hidden_size, num_output):\n",
    "    super().__init__(sr, n_fft, hop_length, n_mels, hidden_size, num_output)\n",
    "    \n",
    "    # TODO: Implement your own model\n",
    "  \n",
    "  def forward(self, x):\n",
    "    # TODO: Implement your own forward pass\n",
    "    return \n",
    "\n",
    "\n",
    "your_model = YourModel(sr=16000, n_fft=1024, hop_length=512, n_mels=48, num_output=50, hidden_size=32)\n",
    "optimizer = torch.optim.Adam(your_model.parameters(), lr=1e-3)\n",
    "your_model = your_model.to(DEV)\n",
    "your_train_record = train_model(your_model, train_loader, valid_loader, optimizer, num_epochs=30, loss_func=loss_func, device=DEV)\n",
    "\n",
    "## Save the figure with comparison of default setting\n",
    "plt.figure(figsize=(8,16))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(train_record['loss'])\n",
    "plt.plot(your_train_record['loss'])\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(train_record['valid_acc'])\n",
    "plt.plot(your_train_record['valid_acc'])\n",
    "save_fig_with_date('comparison_with_default')\n",
    "\n",
    "# Save the model\n",
    "torch.save(your_model.state_dict(), f'your_model_{your_train_record['valid_acc']}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Get the test result\n",
    "'''\n",
    "test_acc = validate_model(your_model, test_loader, DEV)\n",
    "print(f\"Calculated ROC_AUC value for Test Set is : {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: Implement Convolutional Neural Network (20 pts)\n",
    "\n",
    "- Implement the convolutional neural network computation using `nn.Linear` and for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Conv1d with Linear\n",
    "\n",
    "def get_conv1d_output_with_linear(atensor, conv1d_linear, kernel_size):\n",
    "  \n",
    "  batch_size, in_channels, sequence_length = atensor.shape  \n",
    "  # TODO: Implement the forward pass\n",
    "  # Assume stride=1 and padding=0 for simplicity\n",
    "  # To match with the result of nn.Conv1d, flatten the input tensor without changing dimension order\n",
    "  \n",
    "  return\n",
    "\n",
    "# Test the function with different parameters\n",
    "in_channels = 10\n",
    "out_channels = 2\n",
    "kernel_size = 4\n",
    "\n",
    "dummy_input = torch.randn(5, in_channels, 23)\n",
    "\n",
    "conv1d = nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=1, padding=0)\n",
    "output = conv1d(dummy_input)\n",
    "print(output.shape)\n",
    "\n",
    "conv1d_linear = nn.Linear(in_channels * kernel_size, out_channels)\n",
    "conv1d_linear.weight.data = conv1d.weight.data.view(out_channels, -1).clone()\n",
    "conv1d_linear.bias.data = conv1d.bias.data.clone()\n",
    "\n",
    "\n",
    "linear_output = get_conv1d_output_with_linear(dummy_input, conv1d_linear, kernel_size)\n",
    "assert linear_output.shape == output.shape, \"Output tensors have different shapes\"\n",
    "assert torch.allclose(output, linear_output, atol=1e-6), \"Output tensors are different\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Conv2d with Linear\n",
    "\n",
    "def get_conv2d_output_with_linear(atensor, conv2d_linear, kernel_size):\n",
    "  \n",
    "  batch_size, in_channels, height, width = atensor.shape\n",
    "  # TODO: Implement the forward pass\n",
    "  # Assume stride=1 and padding=0 for simplicity\n",
    "  # To match with the result of nn.Conv1d, flatten the input tensor without changing dimension order\n",
    "  \n",
    "  return\n",
    "\n",
    "# Test the function with different parameters\n",
    "in_channels = 10\n",
    "out_channels = 2\n",
    "kernel_size = 4\n",
    "\n",
    "\n",
    "dummy_input = torch.randn(5, in_channels, 13, 17)\n",
    "\n",
    "conv2d = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=1, padding=0)\n",
    "output = conv2d(dummy_input)\n",
    "\n",
    "conv2d_linear = nn.Linear(in_channels * kernel_size * kernel_size, out_channels)\n",
    "conv2d_linear.weight.data = conv2d.weight.data.view(out_channels, -1).clone()\n",
    "conv2d_linear.bias.data = conv2d.bias.data.clone()\n",
    "\n",
    "\n",
    "\n",
    "linear_output = get_conv2d_output_with_linear(dummy_input, conv2d_linear, kernel_size)\n",
    "assert linear_output.shape == output.shape, \"Output tensors have different shapes\"\n",
    "assert torch.allclose(output, linear_output, atol=1e-6), \"Output tensors are different\"\n",
    "print(\"Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_PPNwM1Uj6f"
   },
   "source": [
    "### Problem 4: Complete Binary Cross Entropy Function (5 pts) \n",
    "- Complete the function that can calculate the Binary Cross Entropy for given prediction and target label without using `torch.BCELoss`\n",
    "- $BCE = -\\frac{1}{N} \\sum_{i=1}^{N} y_i \\log(\\hat{y}_i) + (1-y_i) \\log(1-\\hat{y}_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pWhH13CEUj6f"
   },
   "outputs": [],
   "source": [
    "def get_binary_cross_entropy(pred:torch.Tensor, target:torch.Tensor, eps=1e-8):\n",
    "  '''\n",
    "  pred (torch.Tensor): predicted value of a neural network model for a given input (assume that the value is output of sigmoid function)\n",
    "  target (torch.Tensor): ground-truth label for a given input, given in multi-hot encoding\n",
    "\n",
    "  output (torch.Tensor): Mean Binary Cross Entropy Loss value of every sample\n",
    "  '''\n",
    "  # TODO: Complete this function\n",
    "  return\n",
    "\n",
    "test_model = AudioModel(sr=16000, n_fft=1024, hop_length=512, n_mels=48, num_output=50, hidden_size=16)\n",
    "test_model = test_model.to(DEV)\n",
    "test_optimizer = torch.optim.Adam(test_model.parameters(), lr=1e-3)\n",
    "train_record = train_model(test_model, train_loader, valid_loader, test_optimizer, num_epochs=5, loss_func=get_binary_cross_entropy, device=DEV)\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(train_record['loss'])\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(train_record['valid_acc'])\n",
    "save_fig_with_date('handmade_bce_result')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qHpefphaUj6g"
   },
   "source": [
    "### Problem 5. Complete Precision-Recall Area Under Curve Function (20 pts)\n",
    "- One of the frequently used metric is Precision-Recall Area Under Curve (PR-AUC)\n",
    "- Precision is (Number of true positive)/(Number of total positive predictions)\n",
    "- Recall is (Number of true positive)/(Number of total positive ground-truth)\n",
    "- Precision and recall values depend on threshold\n",
    "- PR-AUC is the area under precision-recall curve of varying trheshold\n",
    "  - X-axis is recall, Y-axis is precision\n",
    "  - ![Example of PR curve](https://wiki.cloudfactory.com/media/pages/docs/mp-wiki/metrics/precision-recall-curve-and-auc-pr/6a33324886-1684131968/precision-recall-score-example.webp)\n",
    "- You can refer the pre-defined `get_roc_auc` function\n",
    "  - Instead of trapezoidal rule, use simple **rectangle rule** to calculate the area under curve, following `get_roc_auc` function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "SS9LLkWnUj6g"
   },
   "outputs": [],
   "source": [
    "def get_precision_and_recall(pred:torch.Tensor, target:torch.Tensor, threshold:float):\n",
    "  '''\n",
    "  This function calculates precision and recall of given (prediction, target, threshold)\n",
    "  \n",
    "  pred (torch.Tensor): predicted value of a neural network model for a given input \n",
    "  target (torch.Tensor): ground-truth label for a given input, given in multi-hot encoding\n",
    "\n",
    "  output\n",
    "    precision (torch.Tensor): (Number of true positive)/(Number of total positive predictions)\n",
    "    recall (torch.Tensor): (Number of true positive)/(Number of total positive ground-truth)\n",
    "    \n",
    "  IMPORTANT:\n",
    "    If there is no positive prediction, precision has to be 1\n",
    "    If there is no positive ground-truth, recall has to be 1\n",
    "  \n",
    "  TODO: Complete this function\n",
    "  '''\n",
    "  \n",
    "  # Write your code here\n",
    "  precision, recall = None, None\n",
    "\n",
    "  \n",
    "  '''\n",
    "  Be careful for not returning nan because of division by zero\n",
    "  '''\n",
    "  assert not (torch.isnan(precision) or torch.isnan(recall))\n",
    "  return precision, recall\n",
    "\n",
    "def get_precision_recall_auc(pred:torch.Tensor, target:torch.Tensor, num_grid=500):\n",
    "  '''\n",
    "  This function returns PR_AUC value for a given prediction and target.\n",
    "  Assume pred.shape == target.shape\n",
    "  \n",
    "  pred (torch.Tensor): predicted value of a neural network model for a given input \n",
    "  target (torch.Tensor): ground-truth label for a given input, given in multi-hot encoding\n",
    "\n",
    "  output (torch.Tensor): Area Under Curve value for Precision-Recall Curve, using rectangle method\n",
    "  \n",
    "  TODO: Complete this function using get_precision_and_recall\n",
    "  '''\n",
    "  \n",
    "  auc = 0\n",
    "  prev_recall = 0\n",
    "  for thresh in reversed(torch.linspace(0,1,num_grid)):\n",
    "    precision, recall = get_precision_and_recall(pred, target, threshold=thresh)\n",
    "    auc += precision * (recall - prev_recall)\n",
    "    prev_recall = recall\n",
    "\n",
    "  return auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the test data\n",
    "\n",
    "!wget https://github.com/jdasam/ant5015/raw/refs/heads/2024F/assignment2_data.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Test the get_precision_recall_auc\n",
    "'''\n",
    "\n",
    "# Load the pre-calculated data. Download the data from the link above\n",
    "pre_calculated_data = torch.load('assignment2_data.pt')\n",
    "pre_cal_test_pred = pre_calculated_data['test_pred']\n",
    "pre_cal_test_label = pre_calculated_data['test_label']\n",
    "correct_pr_auc = pre_calculated_data['pr_auc_value_test']\n",
    "correct_pr_curve = pre_calculated_data['pr_curve']\n",
    "\n",
    "\n",
    "'''\n",
    "Printed result of code below has to be tensor(0.1483)\n",
    "'''\n",
    "pr_auc = get_precision_recall_auc(pre_cal_test_pred, pre_cal_test_label) \n",
    "assert torch.allclose(pr_auc, correct_pr_auc, atol=1e-4), \"Result is not correct\"\n",
    "print(\"Passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_model = model\n",
    "pr_auc_value_valid = validate_model(selected_model, valid_loader, DEV, acc_func=get_precision_recall_auc)\n",
    "pr_auc_value_test = validate_model(selected_model, test_loader, DEV, acc_func=get_precision_recall_auc)\n",
    "print(f\"Calculated PR_AUC value for Validation Set is : {pr_auc_value_valid.item():.4f}\")\n",
    "print(f\"Calculated PR_AUC value for Test Set is : {pr_auc_value_test.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_pr_auc_curve(pred:torch.Tensor, target:torch.Tensor, num_grid=500):\n",
    "  '''\n",
    "  This function draws PR curve for given prediction and target.\n",
    "  Assume pred.shape == target.shape\n",
    "  \n",
    "  pred (torch.Tensor): predicted value of a neural network model for a given input \n",
    "  target (torch.Tensor): ground-truth label for a given input, given in multi-hot encoding\n",
    "  '''\n",
    "  pr_curve = []\n",
    "  for thresh in reversed(torch.linspace(0,1,num_grid)):\n",
    "    precision, recall = get_precision_and_recall(pred, target, threshold=thresh)\n",
    "    pr_curve.append((recall, precision))\n",
    "    \n",
    "  pr_curve = torch.tensor(pr_curve)\n",
    "  return pr_curve\n",
    "\n",
    "plt.figure()\n",
    "pr_curve = draw_pr_auc_curve(pre_cal_test_pred, pre_cal_test_label, num_grid=100)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.plot(pr_curve[:,0], pr_curve[:,1])\n",
    "\n",
    "assert torch.allclose(pr_curve, correct_pr_curve, atol=1e-4), \"Result is not correct\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6: Find Best Threshold (15 pts)\n",
    "- For each class, find the best threshold that maximizes the F1 score\n",
    "- F1 score is defined as 2 * (precision * recall) / (precision + recall)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_score(pred:torch.Tensor, target:torch.Tensor, threshold:float):\n",
    "  '''\n",
    "  This function calculates F1 score of given (prediction, target, threshold)\n",
    "  \n",
    "  pred (torch.Tensor): predicted value of a neural network model for a given input \n",
    "  target (torch.Tensor): ground-truth label for a given input, given in multi-hot encoding\n",
    "\n",
    "  output\n",
    "    f1_score (torch.Tensor): 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "  IMPORTANT:\n",
    "    If there is no positive prediction, precision has to be 1\n",
    "    If there is no positive ground-truth, recall has to be 1\n",
    "  '''\n",
    "  \n",
    "  # Write your code here\n",
    "  return\n",
    "\n",
    "\n",
    "f1_score = get_f1_score(pre_cal_test_pred, pre_cal_test_label, threshold=0.2)\n",
    "\n",
    "assert torch.allclose(f1_score, torch.tensor(0.4690), atol=1e-4), \"Result is not correct\"\n",
    "print(\"Passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_threshold_for_each_class(pred:torch.Tensor, target:torch.Tensor, num_grid=100):\n",
    "  '''\n",
    "  This function finds the best threshold for each class to maximize F1 score\n",
    "  \n",
    "  pred (torch.Tensor): predicted value of a neural network model for a given input\n",
    "  target (torch.Tensor): ground-truth label for a given input, given in multi-hot encoding\n",
    "  \n",
    "  output\n",
    "    best_thresholds (torch.Tensor): A tensor of best threshold for each class\n",
    "  '''\n",
    "  \n",
    "  # Write your code here\n",
    "  return\n",
    "\n",
    "\n",
    "best_thresholds = find_best_threshold_for_each_class(pre_cal_test_pred, pre_cal_test_label, num_grid=100)\n",
    "best_thresholds\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.bar(range(50), best_thresholds)\n",
    "plt.xticks(range(50), rotation=70, labels=dummy_set.vocab.tolist())\n",
    "plt.title('Best Threshold for each class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_score_for_each_class(pred, target, best_thresholds):\n",
    "  '''\n",
    "  This function calculates F1 score for each class\n",
    "  \n",
    "  pred (torch.Tensor): predicted value of a neural network model for a given input\n",
    "  target (torch.Tensor): ground-truth label for a given input, given in multi-hot encoding\n",
    "  best_thresholds (torch.Tensor): A tensor of best threshold for each class\n",
    "  \n",
    "  output\n",
    "    f1_scores (torch.Tensor): A tensor of F1 score for each class\n",
    "  '''\n",
    "  \n",
    "  # Write your code here\n",
    "  return\n",
    "\n",
    "\n",
    "f1_scores = get_f1_score_for_each_class(pre_cal_test_pred, pre_cal_test_label, best_thresholds)\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.bar(range(50), f1_scores)\n",
    "plt.xticks(range(50), rotation=70, labels=dummy_set.vocab.tolist())\n",
    "plt.title('F1 Score for each class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now, get best threshold for each class from **VALIDATION** set and apply the threhsold to **TEST** set\n",
    "  - To see the difference, we'll also plot the F1 score of each class with the threshold from the validation set and the threshold from the test set.\n",
    "  - Remember that calculating the threshold from the test set is a sort of cheating. You will get overfitted threshold for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_every_pred_and_label(model:nn.Module, data_loader:DataLoader, device='cuda'):\n",
    "  '''\n",
    "  This function collects every prediction and label of a given model and data_loader\n",
    "  \n",
    "  model (nn.Module): A neural network model\n",
    "  data_loader (DataLoader): A DataLoader object that has test data\n",
    "  \n",
    "  output\n",
    "    every_pred (torch.Tensor): A tensor of every prediction of the model, device has to be 'cpu'\n",
    "    every_label (torch.Tensor): A tensor of every label of the model, device has to be 'cpu'\n",
    "  '''\n",
    "  \n",
    "  # Write your code here\n",
    "  return\n",
    "\n",
    "valid_pred, valid_label = collect_every_pred_and_label(selected_model, valid_loader, DEV)\n",
    "assert valid_pred.device.type == 'cpu', \"Prediction has to be in cpu\"\n",
    "assert valid_label.device.type == 'cpu', \"Label has to be in cpu\"\n",
    "assert len(valid_pred) == len(valid_label), \"Prediction and Label has to have same length\"\n",
    "assert len(valid_pred) == len(validset), \"Prediction has to cover every data in the validset\"\n",
    "\n",
    "test_pred, test_label = collect_every_pred_and_label(selected_model, test_loader, DEV)\n",
    "\n",
    "best_thresholds = find_best_threshold_for_each_class(valid_pred, valid_label, num_grid=100)\n",
    "best_cheating_thresholds = find_best_threshold_for_each_class(test_pred, test_label, num_grid=100) # This is for cheating\n",
    "\n",
    "f1_scores = get_f1_score_for_each_class(test_pred, test_label, best_thresholds)\n",
    "cheating_f1_scores = get_f1_score_for_each_class(test_pred, test_label, best_cheating_thresholds)\n",
    "\n",
    "\n",
    "# Draw the result\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.bar(range(50), f1_scores, width=0.4, align='center', label='F1 Score')\n",
    "# add cheating f1 scores with shifted x-axis\n",
    "plt.bar(range(50), cheating_f1_scores, width=0.4, alpha=0.5, align='edge', label='F1 Score with Cheating Threshold')\n",
    "plt.xticks(range(50), rotation=70, labels=dummy_set.vocab.tolist())\n",
    "plt.title('F1 Score for each class')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93nJtVppUj6g"
   },
   "source": [
    "### Problem 7: Load audio and make prediction (10 pts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "id": "jWXlws--Uj6h"
   },
   "outputs": [],
   "source": [
    "def get_audio_prediction(audio_path:str, model:nn.Module, best_thresholds:torch.Tensor, target_sr=16000):\n",
    "  '''\n",
    "  This function takes an audio path, model, sampling rate, and best_thresholds\n",
    "  and returns the prediction of the model for the audio file.\n",
    "  \n",
    "  audio_path (str): A path of audio file\n",
    "  model (nn.Module): A neural network model\n",
    "  best_thresholds (torch.Tensor): A tensor of best threshold for each class\n",
    "  target_sr (int): Sampling rate of audio file\n",
    "  \n",
    "  output\n",
    "    audio (torch.Tensor): A tensor of audio file\n",
    "    pred (list of str): A list of tags that are predicted to be True\n",
    "  \n",
    "  CAUTION: Do not use external variable to get tag names. Use model.vocab to get tag names\n",
    "  '''\n",
    "  \n",
    "  \n",
    "  return\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "id": "2fMCcJNGUj6g"
   },
   "outputs": [],
   "source": [
    "# your_audio_path = 'your_audio_file_path'\n",
    "your_audio_path = MTAT_DIR / '2/zephyrus-angelus-11-ave_maria__virgo_serena_josquin_des_prez-0-29.mp3'\n",
    "selected_model = model # Change it if you want to select model with different name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gqzRixHZUj6h"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Run Model\n",
    "'''\n",
    "selected_model.to('cpu')\n",
    "selected_model.eval()\n",
    "y, pred = get_audio_prediction(your_audio_path, selected_model)\n",
    "assert type(pred) == list, \"Prediction has to be list\"\n",
    "assert type(pred[0]) == str, \"Each element of prediction has to be string\"\n",
    "assert type(y) == torch.Tensor, \"Audio has to be tensor\"\n",
    "\n",
    "ipd.display(ipd.Audio(y, rate=16000))\n",
    "print(f\"Predicted tags are: {pred}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Creative Technologies Assignment1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
